<!DOCTYPE html>
<html>

<head lang="en">
  <meta charset="UTF-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">

  <title>ReasonNav</title>

  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- <base href="/"> -->
  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bootstrap.min.css">
  <link rel="stylesheet" href="./css/font-awesome.min.css">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="./css/academicons.min.css" />
  <link rel="stylesheet" href="./css/stylesheet.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="./js/jquery.min.js"></script>
  <script src="./js/bootstrap.min.js"></script>
  <script src="./js/app.js"></script>
</head>

<body>
  <br/>
  <br/>
  <div class="container" id="main">
    <div class="row">
      <h2 class="col-md-12 text-center" id="title">
        <strong>Human-like Navigation in a World Built for Humans</strong>
      </h2>
    </div>

    <div class="row">
      <div class="col-sm-10 col-sm-offset-1 text-center">
        <ul class="list-inline">
          <li> <a href="https://bchandaka.github.io/"> Bhargav Chandaka</a><sup>*</sup> </li>
          <li> <a href="https://gxywang.github.io/"> Gloria X. Wang</a><sup>*</sup> </li>
          <li> <a href="https://blog.chenhaozhe.top/"> Haozhe Chen</a> </li>
          <li> <a href="https://hungdche.github.io/"> Henry Che</a> </li>
          <li> <a href="https://ajzhai.github.io/"> Albert J. Zhai</a> </li>
          <li> <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a> </li>
        </ul>
        <ul class="list-inline">
          <li> University of Illinois Urbana-Champaign </li>
        </ul>
        <ul class="list-inline">
          <li> <sup>*</sup> Equal Contribution </li>
      </div>
    </div>

    <div class="row">
      <h2 class="col-md-12 text-center" id="venue" style="font-size:1.75em; margin-top: 2px; margin-bottom: 20px;">
        <strong>CoRL 2025</strong>
      </h2>
    </div>

    <div class="row">
      <div class="col-sm-8 col-sm-offset-2 text-center">
        <span class="link-block">
          <a href="assets/paper.pdf" class="external-link button is-large is-rounded is-dark">
            <span class="icon">
              <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas"
                data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="-24 -32 432 576"
                data-fa-i2svg="">
                <path fill="currentColor"
                  d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                </path>
              </svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
            </span>
            <span>Paper</span>
          </a>
        </span> &nbsp;
        <span class="link-block">
          <a href="https://arxiv.org/abs/2509.21189v1" class="external-link button is-large is-rounded is-dark box-shadow">
            <span class="icon">
              <i class="ai ai-arxiv ai-2x" aria-hidden="true"></i>
            </span>
            <span>arXiv</span>
          </a>
        </span> &nbsp;
        <span class="link-block">
          <a href="https://github.com/ReasonNav/ReasonNav" class="external-link button is-large is-rounded is-dark">
            <span class="icon" >
              <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab"
                data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg="">
                <path fill="currentColor"
                  d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                </path>
              </svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
            </span>
            <span>Code</span>
          </a>
        </span>
      </div>
    </div>

    <!-- Abstraction, Overview figure-->
    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <div class="video-wrapper">
          <div class="ytp-muted-autoplay-bottom-buttons">
            <button class="audioToggle custom-button" aria-label="Unmute">
              <span class="custom-button-icon">ðŸ”‡</span>
              <span class="custom-button-text">Unmute</span>
            </button>
          </div>
          <video class="video" controls autoplay loop muted playsinline style="display: block; max-width: 100%;">
            <source src="./assets/video.mp4" type="video/mp4">
          </video>
        </div>
        <br>
        <br/>

        <h3>
          <b>Abstract</b>
        </h3>
        <p class="text-justify">
          When navigating in a man-made environment they haven't visited 
          beforeâ€”like an office buildingâ€”humans employ behaviors such
          as reading signs and asking others for directions. These 
          behaviors help humans reach their destinations efficiently by 
          reducing the need to search through large areas. 
          Existing robot navigation systems lack the ability to
          execute such behaviors and are thus highly inefficient at
          navigating within large environments. We present ReasonNav, 
          a modular navigation system which integrates these
          human-like navigation skills by leveraging the reasoning
          capabilites of a vision-language model (VLM). We design
          compact input and output abstractions based on navigation
          landmarks, allowing the VLM to focus on language understanding 
          and reasoning. We evaluate ReasonNav on real and simulated
          navigation tasks and show that the agent successfully 
          employs higher-order reasoning to navigate efficiently in large, complex buildings.
        </p>
      </div>
      <br/>

      <div class="col-md-10 col-md-offset-1">
        <br/>

        <h3>
          <b>Method</b>
        </h3>
        <div class="key-idea-box">
          <div class="key-idea-label">ðŸ’¡ Key Idea</div>
          <p class="key-idea-text">
            We let a VLM agent choose navigation landmarks, leveraging its reasoning
            abilities to recognize patterns like ascending room numbers, while abstracting
            away details regarding complex spatial data and precise numerical control.
          </p>
        </div>
        <p class="text-justify">
          <b>ReasonNav</b> is a modular system that integrates human-like navigation behaviors through a Vision-Language Model (VLM) agent. 
          While VLMs excel at language understanding and commonsense reasoning, they struggle with complex spatial data and precise numerical outputs. 
          To address this, we design compact input and output abstractions centered on the concept of landmarksâ€”salient objects critical for navigation, 
          including doors, people, directional signs, and map frontiers. 
        </p>
        <br/>
        <div class="text-center">
          <image src="./assets/method.png" class="img-responsive" alt="teaser" 
          style="max-width: 80%; height: auto; width: auto;"/>
        </div>
        <br/>
        <p class="text-justify">
          Our system maintains a memory bank that stores detected landmarks along with navigation-relevant information gathered through interaction. 
          For doors, we attach room label text; for people, we store summaries of directions they provide; 
          for signs, we record cardinal directions and their associated text. The VLM receives this information in two forms: 
          a JSON-formatted memory bank and a top-down map visualization with landmarks plotted by category and index. 
          Based on the VLM's selection, ReasonNav executes predefined behavior primitives tailored to each landmark type.  
          <br/><br/>
          This design enables the VLM to employ higher-order reasoningâ€”such as following ascending room numbers or interpreting directional signsâ€”
          without being burdened by low-level control. The modular architecture separates high-level decision-making (VLM-driven) from 
          low-level execution (localization, mapping, and path planning), allowing ReasonNav to navigate efficiently in large, complex environments
          through human-like exploration strategies. 
        </p>
        <br/>
      </div>
      <br/>

      <div class="col-md-10 col-md-offset-1">
        <br/>

        <h3>
          <b>Walkthrough</b>
        </h3>
        <div class="video-wrapper">
          <div class="ytp-muted-autoplay-bottom-buttons">
            <button class="audioToggle custom-button" aria-label="Unmute">
              <span class="custom-button-icon">ðŸ”‡</span>
              <span class="custom-button-text">Unmute</span>
            </button>
          </div>
          <video class="video" controls autoplay loop muted playsinline style="display: block; max-width: 100%;">
            <source src="./assets/reasonnav_walkthrough.mp4" type="video/mp4">
          </video>
        </div>
        <br/>
        <p class="text-justify">
          In this video, we show a successful demonstration of ReasonNav delivering a water bottle to a Professor's office
          in an unknown environment. The target room number obtained algorithmically via a simple web search of the Professor's office. 
          Step-by-step reasoning of the VLM is shown in addition to a birds-eye-view map and the Realsense camera view.
        </p>
        <br/>
      </div>
      <br/>

      <div class="col-md-10 col-md-offset-1">
        <br/>
        <h3>
          <b>Skills</b>
        </h3>
        <p class="text-justify">
          Based on the selected navigation landmark, the robot will execute one of four
          behavior primitives: reading signs, reading room numbers, asking people for directions,
          and exploring frontiers.
        </p>
        <br/>
        
        <div class="row">
          <!-- First row - 2 videos -->
          <div class="col-md-6">
            <div class="text-center">
              <p>
                <b>Read Signs</b>
              </p>
              <image src="./assets/reasonnav_readsigns.gif" class="img-responsive" alt="read signs" 
              style="height: auto; width: 100%;"/>
            </div>
          </div>
          
          <div class="col-md-6">
            <div class="text-center">
              <p>
                <b>Check Doors</b>
              </p>
              <image src="./assets/reasonnav_roomnumber.gif" class="img-responsive" alt="room number" 
              style="height: auto; width: 100%;"/>
            </div>
          </div>
        </div>
        
        <div class="row">
          <!-- Second row - 2 videos -->
          <div class="col-md-6">
            <div class="video-wrapper">
              <div class="ytp-muted-autoplay-bottom-buttons" style="display: flex; align-items: center; gap: 16%;">
                <button class="audioToggle custom-button" aria-label="Unmute">
                  <span class="custom-button-icon">ðŸ”‡</span>
                  <span class="custom-button-text">Unmute</span>
                </button>
                <p style="margin: 0; text-align: center;">
                  <b>Ask People</b>
                </p>
              </div>
              <video class="video" controls autoplay loop muted playsinline style="display: block; max-width: 100%;">
                <source src="./assets/reasonnav_askpeople.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="col-md-6">
            <div class="text-center" style="padding-top: 12px;">
              <p>
                <b>Explore Frontiers</b>
              </p>
              <image src="./assets/reasonnav_frontier.gif" class="img-responsive" alt="frontier" 
              style="height: auto; width: 100%;"/>
            </div>
          </div>
        </div>
        <br/>
      </div>
      <br/>

      <div class="col-md-10 col-md-offset-1">
        <br/>

        <h3>
          <b>Examples</b>
        </h3>
        <div class="row">
          <!-- First row - 2 videos -->
          <div class="col-md-6">
            <div class="video-wrapper">
              <div class="ytp-muted-autoplay-bottom-buttons" style="display: flex; align-items: center; gap: 22%;">
                <button class="audioToggle custom-button" aria-label="Unmute">
                  <span class="custom-button-icon">ðŸ”‡</span>
                  <span class="custom-button-text">Unmute</span>
                </button>
                <p style="margin: 0; text-align: center;">
                  <b>Real</b>
                </p>
              </div>
              <video class="video" controls autoplay loop muted playsinline style="display: block; max-width: 100%;">
                <source src="./assets/reasonnav_demo1.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          
          <div class="col-md-6">
            <div class="video-wrapper">
              <div class="ytp-muted-autoplay-bottom-buttons" style="display: flex; align-items: center; gap: 22%;">
                <button class="audioToggle custom-button" aria-label="Unmute">
                  <span class="custom-button-icon">ðŸ”‡</span>
                  <span class="custom-button-text">Unmute</span>
                </button>
                <p style="margin: 0; text-align: center;">
                  <b>Sim</b>
                </p>
              </div>
              <video class="video" controls autoplay loop muted playsinline style="display: block; max-width: 100%;">
                <source src="./assets/reasonnav_demosim.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>

        <br/> <br/>
        <div class="text-center">
          <h4>
            <b>Multi-floor Example</b>
          </h4>
        </div>
        <div class="video-wrapper">
          <div class="ytp-muted-autoplay-bottom-buttons" style="display: flex; align-items: center; gap: 22%;">
            <button class="audioToggle custom-button" aria-label="Unmute">
              <span class="custom-button-icon">ðŸ”‡</span>
              <span class="custom-button-text">Unmute</span>
            </button>
          </div>
          <video class="video" controls autoplay loop muted playsinline style="display: block; max-width: 100%;">
            <source src="./assets/reasonnav_elevatordemo.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <br/>
      </div>
      <br/>

      <div class="col-md-10 col-md-offset-1">
        <br/>
        <h3>
          <b>Citation</b>
        </h3>
        <p>If you find our work useful in your research, please consider citing:</p>
        <div style="background-color: #9e9e9e1a; border-radius: 20px; position: relative; overflow-x: auto;">
          <p style="font-family: monospace; font-size: 13px; line-height: 1.6; white-space: pre; word-wrap: break-word;">
    @inproceedings{chandaka2025reasonnav,
      author={Chandaka, Bhargav and Wang, Gloria and Chen, Haozhe and Che, Henry and Zhai, Albert and Wang, Shenlong},
      title={Human-like Navigation in a World Built for Humans}, 
      booktitle={Conference on Robot Learning},
      year={2025}
    }</p>
          </div>
          <br/>
      </div>
      <br/>

      <div class="col-md-10 col-md-offset-1">
        <br/>
        <h3>
          <b>Acknowledgements</b>
        </h3>
        <p>
          The website template was borrowed from <a href="https://climatenerf.github.io/">ClimateNerf</a> and <a
          href="https://Sim-on-Wheels.github.io/">Sim-on-Wheels</a>.
        </p>
      </div>
    </div>
  </div>
  <br>

  <script>
    var textarea = document.getElementById('codemirror');
    textarea.addEventListener('input', autoResize, false);

    function autoResize() {
      this.style.height = 'auto';
      this.style.height = this.scrollHeight + 'px';

      // Set the width
      var scrollWidth = this.scrollWidth;
      this.style.width = scrollWidth + 'px';
    }

    // Call the function initially to resize on page load
    autoResize.call(textarea);
  </script>

  <script>
    const videoWrappers = document.querySelectorAll('.video-wrapper');

    videoWrappers.forEach(wrapper => {
      const video = wrapper.querySelector('.video');
      const audioBtn = wrapper.querySelector('.audioToggle');
      const btnIcon = audioBtn.querySelector('.custom-button-icon');
      const btnText = audioBtn.querySelector('.custom-button-text');

      audioBtn.addEventListener('click', function() {
        if (video.muted) {
          video.muted = false;
          btnIcon.textContent = 'ðŸ”Š';
          btnText.textContent = 'Mute';
          audioBtn.setAttribute('aria-label', 'Mute');
        } else {
          video.muted = true;
          btnIcon.textContent = 'ðŸ”‡';
          btnText.textContent = 'Unmute';
          audioBtn.setAttribute('aria-label', 'Unmute');
        }
      });
    });
  </script>
</body>

</html>